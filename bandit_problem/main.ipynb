{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5edc59b",
   "metadata": {},
   "source": [
    "## 3本のスロットマシン問題\n",
    "\n",
    "#### 状況\n",
    "- エージェントは３本のスロットマシンを前にしています\n",
    "- 各スロットマシンには異なる確率で報酬(+1)が出ます\n",
    "\n",
    "    | マシンの種類 | 報酬が出る確率 |\n",
    "    | :---         | :---           |\n",
    "    |A | 0.2 |\n",
    "    |B | 0.5 |\n",
    "    |C | 0.8 |\n",
    "\n",
    "#### エージェントの目的\n",
    "- できるだけ多くの報酬を得ること\n",
    "- どのマシンが一番報酬を得られるかを学習していく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0cc460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a746e2b",
   "metadata": {},
   "source": [
    "## Q値の更新ルール\n",
    "#### 状況\n",
    "- 各マシンの行動に対して、エージェントは「そのマシンの価値(Q値)」を保持している\n",
    "- 経験を重ねながら、このQ値を少しずつ**本当の期待値に近づける**ことが目的\n",
    "\n",
    "#### 更新式\n",
    "$Q_{new}(a) = Q_{old}(a) + \\alpha \\times (r-Q_{old}(a))$\n",
    "- 今の評価に**新しい経験との差分**を少しだけ加えて更新する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd5504",
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD = 1\n",
    "MACHINE_TYPE = ['A', 'B', 'C']\n",
    "\n",
    "# マシンの報酬をランダムに発生させる関数\n",
    "def get_reward(machine_type: str):\n",
    "    if machine_type=='A':\n",
    "        return np.random.choice([0, REWARD], p=[0.8, 0.2])\n",
    "    elif machine_type=='B':\n",
    "        return np.random.choice([0, REWARD], p=[0.5, 0.5])\n",
    "    elif machine_type=='C':\n",
    "        return np.random.choice([0, REWARD], p=[0.2, 0.8])\n",
    "    else:\n",
    "        print(f'{machine_type} is not be able to use as args...')\n",
    "        return None\n",
    "\n",
    "# ε-greedyでマシンを選ぶ関数\n",
    "def choice_machine(q_table, epsilon=0.2)-> str: \n",
    "    # 探索\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.choice(MACHINE_TYPE)\n",
    "    # 活用\n",
    "    else:\n",
    "        return max(q_table, key=q_table.get)\n",
    "\n",
    "# Q値の更新ルール\n",
    "def update_q(q_table:list, machine_type:str, reward:int, lr=0.05)->dict:\n",
    "    q_table[machine_type] += lr * (reward - q_table[machine_type])\n",
    "    return q_table \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39555233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q-tableの初期化\n",
    "q_table = { 'A': 0.0, 'B': 0.0, 'C': 0.0 }\n",
    "# ハイパパラメータ\n",
    "steps = 1_000\n",
    "epsilon = 0.2\n",
    "lr = 0.05\n",
    "\n",
    "\n",
    "# 学習確認用\n",
    "rewards = []\n",
    "counts_machine = {'A': 0, 'B': 0, 'C': 0}\n",
    "\n",
    "for i in range(steps):\n",
    "    # マシンの選択\n",
    "    machine_type = choice_machine(q_table=q_table,\n",
    "                                  epsilon=epsilon)\n",
    "\n",
    "    # 報酬獲得\n",
    "    is_reward = get_reward(machine_type=machine_type)\n",
    "\n",
    "    # Q-tableの更新\n",
    "    q_table = update_q(q_table=q_table, \n",
    "                       machine_type=machine_type, \n",
    "                       reward=is_reward, \n",
    "                       lr=lr)\n",
    "\n",
    "    # データ格納\n",
    "    rewards.append(is_reward)\n",
    "    counts_machine[machine_type] += 1\n",
    "\n",
    "print(q_table)\n",
    "print(counts_machine)\n",
    "\n",
    "# 報酬の可視化\n",
    "window = 20\n",
    "moving_avg = np.convolve(rewards, np.ones(window)/window, mode='valid')\n",
    "\n",
    "plt.plot(moving_avg)\n",
    "plt.xlabel(\"試行（step）\")\n",
    "plt.ylabel(\"移動平均報酬\")\n",
    "plt.title(\"報酬の推移（移動平均）\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15365495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_q_heatmap(q_table):\n",
    "    machines = list(q_table.keys())\n",
    "    q_values = list(q_table.values())\n",
    "    \n",
    "    # Seabornスタイルで棒グラフ風ヒートマップ\n",
    "    plt.figure(figsize=(6, 1.5))\n",
    "    sns.heatmap([q_values], annot=True, fmt=\".2f\", cmap=\"YlGnBu\", xticklabels=machines, yticklabels=[\"Q値\"])\n",
    "    \n",
    "    plt.title(\"Q値のヒートマップ\")\n",
    "    plt.show()\n",
    "\n",
    "plot_q_heatmap(q_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_platform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
