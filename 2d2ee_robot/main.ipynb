{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c223c843",
   "metadata": {},
   "source": [
    "## DQNを用いた二自由度マニピュレータの動作計画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419f9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "from env import Arm2DEnv\n",
    "from dqn import DQN\n",
    "from buffer import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815484ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行動を選択(ε-greedy法を使用)\n",
    "def select_action(model, state, action_dim, epsilon=0.2):\n",
    "    # 探索\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(action_dim)\n",
    "    \n",
    "    # 活用\n",
    "    state = torch.FloatTensor(state).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        q_values = model(state) # 各行動のq値を取得 (action_dim, )\n",
    "    return q_values.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ループ\n",
    "def train():\n",
    "    # 環境とハイパパラメータのセット\n",
    "    env = Arm2DEnv()\n",
    "    input_dim = len(env.get_state())\n",
    "    action_dim = len(env.action_space)\n",
    "\n",
    "    # DQNとtarget networkを設定する\n",
    "    model = DQN(input_dim, action_dim)\n",
    "    target_network = DQN(input_dim, action_dim)\n",
    "    target_network.load_state_dict(model.state_dict()) # モデルと同じパラメータにさせる\n",
    "\n",
    "    # 最適化アルゴリズムのセット\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # ハイパパラメータ\n",
    "    batch_size = 64\n",
    "    gamma = 0.99\n",
    "    epsilon = 1.0\n",
    "    epsilon_min = 0.1\n",
    "    epsilon_decay = 0.995\n",
    "    target_update_freq = 10\n",
    "\n",
    "    episodes = 1_000\n",
    "    max_steps = 50\n",
    "\n",
    "    # バッファのセット\n",
    "    buffer = ReplayBuffer(batch_size)\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            # ε-greedyで行動選択\n",
    "            action = select_action(model, state, action_dim, epsilon)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_platform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
